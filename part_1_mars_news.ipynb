{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: webdriver_manager in c:\\users\\jrgar\\anaconda3\\envs\\pythondata\\lib\\site-packages (3.8.5)\n",
      "Requirement already satisfied: selenium in c:\\users\\jrgar\\anaconda3\\envs\\pythondata\\lib\\site-packages (4.7.2)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\jrgar\\anaconda3\\envs\\pythondata\\lib\\site-packages (from webdriver_manager) (0.21.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\jrgar\\appdata\\roaming\\python\\python37\\site-packages (from webdriver_manager) (21.3)\n",
      "Requirement already satisfied: requests in c:\\users\\jrgar\\anaconda3\\envs\\pythondata\\lib\\site-packages (from webdriver_manager) (2.28.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\jrgar\\anaconda3\\envs\\pythondata\\lib\\site-packages (from webdriver_manager) (4.64.1)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\jrgar\\anaconda3\\envs\\pythondata\\lib\\site-packages (from selenium) (0.9.2)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\jrgar\\anaconda3\\envs\\pythondata\\lib\\site-packages (from selenium) (2022.12.7)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\jrgar\\anaconda3\\envs\\pythondata\\lib\\site-packages (from selenium) (0.22.0)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in c:\\users\\jrgar\\anaconda3\\envs\\pythondata\\lib\\site-packages (from selenium) (1.26.14)\n",
      "Requirement already satisfied: sniffio in c:\\users\\jrgar\\anaconda3\\envs\\pythondata\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\jrgar\\anaconda3\\envs\\pythondata\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\users\\jrgar\\anaconda3\\envs\\pythondata\\lib\\site-packages (from trio~=0.17->selenium) (1.1.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\jrgar\\anaconda3\\envs\\pythondata\\lib\\site-packages (from trio~=0.17->selenium) (22.1.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\jrgar\\anaconda3\\envs\\pythondata\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\jrgar\\anaconda3\\envs\\pythondata\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: outcome in c:\\users\\jrgar\\anaconda3\\envs\\pythondata\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: idna in c:\\users\\jrgar\\anaconda3\\envs\\pythondata\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\jrgar\\anaconda3\\envs\\pythondata\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\jrgar\\anaconda3\\envs\\pythondata\\lib\\site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\jrgar\\appdata\\roaming\\python\\python37\\site-packages (from packaging->webdriver_manager) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jrgar\\anaconda3\\envs\\pythondata\\lib\\site-packages (from requests->webdriver_manager) (2.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\jrgar\\appdata\\roaming\\python\\python37\\site-packages (from tqdm->webdriver_manager) (0.4.6)\n",
      "Requirement already satisfied: pycparser in c:\\users\\jrgar\\anaconda3\\envs\\pythondata\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\jrgar\\anaconda3\\envs\\pythondata\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\jrgar\\anaconda3\\envs\\pythondata\\lib\\site-packages (from h11<1,>=0.9.0->wsproto>=0.14->trio-websocket~=0.9->selenium) (4.4.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install webdriver_manager selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Splinter and BeautifulSoup\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as soup\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Send a request to the Mars NASA news site\n",
    "url = \"https://redplanetscience.com\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content with BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # Create an empty list to store the dictionaries\n",
    "    news_list = []\n",
    "\n",
    "    # Extract the titles and preview text and store them in the list of dictionaries\n",
    "    articles = soup.find_all(\"div\", class_=\"list_text\")\n",
    "\n",
    "    for article in articles:\n",
    "        title = article.find(\"div\", class_=\"content_title\").text.strip()\n",
    "        preview = article.find(\"div\", class_=\"article_teaser_body\").text.strip()\n",
    "\n",
    "        news_dict = {'title': title, 'preview': preview}\n",
    "        news_list.append(news_dict)\n",
    "\n",
    "    # Print the list of dictionaries\n",
    "    for news_item in news_list:\n",
    "        print(news_item)\n",
    "else:\n",
    "    print(f\"Failed to fetch the page. Status Code: {response.status_code}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jrgar\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: NASA's Perseverance Rover Sees Mars in a New Light\n",
      "Summary: \n",
      "\n",
      "Title: Ancient River Is Helping NASA's Perseverance Mars Rover Do Its Work\n",
      "Summary: \n",
      "\n",
      "Title: NASA's Ingenuity Mars Helicopter Phones Home\n",
      "Summary: \n",
      "\n",
      "Title: NASA's MAVEN Spacecraft Stuns with Ultraviolet Views of Red Planet\n",
      "Summary: \n",
      "\n",
      "Title: Landing in Living Rooms: LEGO Models of NASA Mars Rover and Helicopter\n",
      "Summary: \n",
      "\n",
      "Title: NASA's Curiosity Captures Martian Morning, Afternoon in New 'Postcard'\n",
      "Summary: \n",
      "\n",
      "Title: Why – and How – NASA Gives a Name to Every Spot It Studies on Mars\n",
      "Summary: \n",
      "\n",
      "Title: NASA's Perseverance Rover Captures View of Mars' Belva Crater\n",
      "Summary: \n",
      "\n",
      "Title: Images From NASA's Perseverance May Show Record of Wild Martian River\n",
      "Summary: \n",
      "\n",
      "Title: NASA Retires Mineral Mapping Instrument on Mars Orbiter\n",
      "Summary: \n",
      "\n",
      "Title: NASA InSight Study Provides Clearest Look Ever at Martian Core\n",
      "Summary: \n",
      "\n",
      "Title: NASA Selects 10 Scientists for International Mission to Martian Moons\n",
      "Summary: \n",
      "\n",
      "Title: NASA's Ingenuity Mars Helicopter Completes 50th Flight\n",
      "Summary: \n",
      "\n",
      "Title: NASA's Curiosity Mars Rover Gets a Major Software Upgrade\n",
      "Summary: \n",
      "\n",
      "Title: NASA to Convene Mars Sample Return Review\n",
      "Summary: \n",
      "\n",
      "Title: New Interactive Mosaic Uses NASA Imagery to Show Mars in Vivid Detail\n",
      "Summary: \n",
      "\n",
      "Title: NASA's Perseverance Collects First Mars Sample of New Science Campaign\n",
      "Summary: \n",
      "\n",
      "Title: Engineers Keep an Eye on Fuel Supply of NASA's Oldest Mars Orbiter\n",
      "Summary: \n",
      "\n",
      "Title: NASA's Curiosity Views First 'Sun Rays' on Mars\n",
      "Summary: \n",
      "\n",
      "Title: NASA's Perseverance Rover Set to Begin Third Year at Jezero Crater\n",
      "Summary: \n",
      "\n",
      "Title: NASA's Perseverance Rover Shows Off Collection of Mars Samples\n",
      "Summary: \n",
      "\n",
      "Title: NASA's Curiosity Finds Surprise Clues to Mars' Watery Past\n",
      "Summary: \n",
      "\n",
      "Title: NASA's Perseverance Rover Completes Mars Sample Depot\n",
      "Summary: \n",
      "\n",
      "Title: NASA Explores a Winter Wonderland on Mars\n",
      "Summary: \n",
      "\n",
      "Title: NASA's Perseverance Rover Deposits First Sample on Mars Surface\n",
      "Summary: \n",
      "\n",
      "Title: NASA Retires InSight Mars Lander Mission After Years of Science\n",
      "Summary: \n",
      "\n",
      "Title: NASA's Perseverance Rover to Begin Building Martian Sample Depot\n",
      "Summary: \n",
      "\n",
      "Title: NASA's Perseverance Rover Gets the Dirt on Mars\n",
      "Summary: \n",
      "\n",
      "Title: NASA's Perseverance Rover Investigates Intriguing Martian Bedrock\n",
      "Summary: \n",
      "\n",
      "Title: NASA's MAVEN Observes Martian Light Show Caused by Major Solar Storm\n",
      "Summary: \n",
      "\n",
      "Title: NASA Prepares to Say 'Farewell' to InSight Spacecraft\n",
      "Summary: \n",
      "\n",
      "Title: NASA and ESA Agree on Next Steps to Return Mars Samples to Earth\n",
      "Summary: \n",
      "\n",
      "Title: NASA's InSight Lander Detects Stunning Meteoroid Impact on Mars\n",
      "Summary: \n",
      "\n",
      "Title: NASA To Host Briefing on InSight, Mars Reconnaissance Orbiter Findings\n",
      "Summary: \n",
      "\n",
      "Title: Why NASA Is Trying To Crash Land on Mars\n",
      "Summary: \n",
      "\n",
      "Title: Curiosity Mars Rover Reaches Long-Awaited Salty Region\n",
      "Summary: \n",
      "\n",
      "Title: Mars Mission Shields Up for Tests\n",
      "Summary: \n",
      "\n",
      "Title: NASA's InSight Waits Out Dust Storm\n",
      "Summary: \n",
      "\n",
      "Title: NASA's InSight 'Hears' Its First Meteoroid Impacts on Mars\n",
      "Summary: \n",
      "\n",
      "Title: NASA's Perseverance Rover Investigates Geologically Rich Mars Terrain\n",
      "Summary: \n",
      "\n",
      "Title: \n",
      "Summary: \n",
      "\n",
      "Title: \n",
      "Summary: \n",
      "\n",
      "Title: \n",
      "Summary: \n",
      "\n",
      "Title: NASA InSight Study Provides Clearest Look Ever at Martian Core\n",
      "Summary: \n",
      "\n",
      "Title: NASA's Perseverance Rover Completes Mars Sample Depot\n",
      "Summary: \n",
      "\n",
      "Title: NASA's Perseverance Rover Deposits First Sample on Mars Surface\n",
      "Summary: \n",
      "\n",
      "Title: \n",
      "Summary: \n",
      "\n",
      "Title: \n",
      "Summary: \n",
      "\n",
      "Title: \n",
      "Summary: \n",
      "\n",
      "Title: \n",
      "Summary: \n",
      "\n",
      "Title: \n",
      "Summary: \n",
      "\n",
      "Title: \n",
      "Summary: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# Set up the Chrome browser\n",
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = webdriver.Chrome(**executable_path)\n",
    "\n",
    "# Navigate to the Mars NASA news site\n",
    "url = \"https://mars.nasa.gov/news/\"\n",
    "browser.get(url)\n",
    "\n",
    "# Wait for the page to load (optional)\n",
    "# You can use explicit waits or sleep for a few seconds\n",
    "\n",
    "# Find and extract the elements (article titles and summaries)\n",
    "articles = browser.find_elements(By.CLASS_NAME, \"slide\")\n",
    "\n",
    "for article in articles:\n",
    "    title_element = article.find_element(By.CLASS_NAME, \"content_title\")\n",
    "    summary_element = article.find_element(By.CLASS_NAME, \"rollover_description_inner\")\n",
    "\n",
    "    title = title_element.text.strip()\n",
    "    summary = summary_element.text.strip()\n",
    "\n",
    "    print(f\"Title: {title}\\nSummary: {summary}\\n\")\n",
    "\n",
    "# Close the browser\n",
    "browser.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visit the Mars NASA news site: https://redplanetscience.com\n",
    "url = \"https://redplanetscience.com\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # Identify the elements to scrape (article titles and summaries)\n",
    "    articles = soup.find_all(\"div\", class_=\"list_text\")\n",
    "\n",
    "    # Extract the data and print\n",
    "    for article in articles:\n",
    "        title = article.find(\"div\", class_=\"content_title\").text.strip()\n",
    "        summary = article.find(\"div\", class_=\"article_teaser_body\").text.strip()\n",
    "\n",
    "        print(f\"Title: {title}\\nSummary: {summary}\\n\")\n",
    "else:\n",
    "    print(f\"Failed to fetch the page. Status Code: {response.status_code}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Beautiful Soup object\n",
    "\n",
    "# Send a request to the Mars NASA news site\n",
    "url = \"https://redplanetscience.com\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request successful\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content with BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # Identify elements to scrape (article titles and summaries)\n",
    "    articles = soup.find_all(\"div\", class_=\"list_text\")\n",
    "\n",
    "    # Extract data + print\n",
    "    for article in articles:\n",
    "        title = article.find(\"div\", class_=\"content_title\").text.strip()\n",
    "        summary = article.find(\"div\", class_=\"article_teaser_body\").text.strip()\n",
    "\n",
    "        print(f\"Title: {title}\\nSummary: {summary}\\n\")\n",
    "else:\n",
    "    print(f\"Failed to fetch the page. Status Code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "News - Mars Exploration Program MARS Planet Science Exploration Program The Red Planet The Program News & Events Multimedia Missions More News Latest All Categories More You Might Also Like NASA to Broadcast Mars 2020 Perseverance Launch, Prelaunch Activities The Launch Is Approaching for NASA's Next Mars Rover, Perseverance NASA to Hold Mars 2020 Perseverance Rover Launch Briefing With supporting text below as a natural lead-in to additional content. With supporting text below as a natural lead-in to additional content. With supporting text below as a natural lead-in to additional content. With supporting text below as a natural lead-in to additional content. With supporting text below as a natural lead-in to additional content. With supporting text below as a natural lead-in to additional content. The Red Planet Dashboard Science Goals The Planet The Program Mission Statement About the Program Organization Why Mars? Multimedia Images Videos More Resources Missions Past Present Future\n"
     ]
    }
   ],
   "source": [
    "# Extract all the text elements\n",
    "\n",
    "url = \"https://redplanetscience.com\"\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content with BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # Extract all text elements and print\n",
    "    all_text_elements = soup.get_text(strip=True, separator=\" \")\n",
    "    print(all_text_elements)\n",
    "else:\n",
    "    print(f\"Failed to fetch the page. Status Code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://redplanetscience.com\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content with BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # Extract the titles and preview text and store them in a list of dictionaries\n",
    "    articles = soup.find_all(\"div\", class_=\"list_text\")\n",
    "\n",
    "    news_list = []\n",
    "    for article in articles:\n",
    "        title = article.find(\"div\", class_=\"content_title\").text.strip()\n",
    "        preview = article.find(\"div\", class_=\"article_teaser_body\").text.strip()\n",
    "\n",
    "        news_dict = {'title': title, 'preview': preview}\n",
    "        news_list.append(news_dict)\n",
    "\n",
    "    # Print the list of dictionaries\n",
    "    for news_item in news_list:\n",
    "        print(news_item)\n",
    "else:\n",
    "    print(f\"Failed to fetch the page. Status Code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\jrgar\\anaconda3\\envs\\pythondata\\lib\\site-packages (2.28.2)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\jrgar\\anaconda3\\envs\\pythondata\\lib\\site-packages (4.11.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\jrgar\\anaconda3\\envs\\pythondata\\lib\\site-packages (from requests) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jrgar\\anaconda3\\envs\\pythondata\\lib\\site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jrgar\\anaconda3\\envs\\pythondata\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jrgar\\anaconda3\\envs\\pythondata\\lib\\site-packages (from requests) (2022.12.7)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\jrgar\\anaconda3\\envs\\pythondata\\lib\\site-packages (from beautifulsoup4) (2.3.2.post1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store the dictionaries\n",
    "url = \"https://redplanetscience.com\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content with BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # Create an empty list to store the dictionaries\n",
    "    news_list = []\n",
    "\n",
    "    # Extract the titles and preview text and store them in the list of dictionaries\n",
    "    articles = soup.find_all(\"div\", class_=\"list_text\")\n",
    "\n",
    "    for article in articles:\n",
    "        title = article.find(\"div\", class_=\"content_title\").text.strip()\n",
    "        preview = article.find(\"div\", class_=\"article_teaser_body\").text.strip()\n",
    "\n",
    "        news_dict = {'title': title, 'preview': preview}\n",
    "        news_list.append(news_dict)\n",
    "\n",
    "    # Print the list of dictionaries\n",
    "    for news_item in news_list:\n",
    "        print(news_item)\n",
    "else:\n",
    "    print(f\"Failed to fetch the page. Status Code: {response.status_code}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to fetch the page. Status Code: 200\n"
     ]
    }
   ],
   "source": [
    "# Loop through the text elements\n",
    "\n",
    "\n",
    "# Send a request to the Mars NASA news site\n",
    "url = \"https://redplanetscience.com\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content with BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # Create an empty list to store the dictionaries\n",
    "    news_list = []\n",
    "    \n",
    "# Extract the title and preview text from the elements\n",
    "    all_text_elements = soup.get_text(strip=True, separator=\" \")\n",
    "    for element in all_text_elements.split():\n",
    "        # Check if the element contains \"title\" and \"preview\" text\n",
    "        if \"title\" in element.lower() and \"preview\" in element.lower():\n",
    "            # Store each title and preview pair in a dictionary\n",
    "            title = element.replace(\"Title:\", \"\").strip()\n",
    "            preview = all_text_elements.split(\"Preview:\", 1)[1].strip()\n",
    "            \n",
    "            # Add the dictionary to the list\n",
    "            \n",
    "            news_dict = {'title': title, 'preview': preview}\n",
    "            news_list.append(news_dict)\n",
    "\n",
    "\n",
    "for news_item in news_list:\n",
    "        print(news_item)\n",
    "else:\n",
    "    print(f\"Failed to fetch the page. Status Code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to fetch the page. Status Code: 200\n"
     ]
    }
   ],
   "source": [
    "# Print the list to confirm success\n",
    "for news_item in news_list:\n",
    "        print(news_item)\n",
    "else:\n",
    "    print(f\"Failed to fetch the page. Status Code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymongoNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading pymongo-4.4.1-cp37-cp37m-win_amd64.whl (407 kB)\n",
      "     -------------------------------------- 407.6/407.6 kB 3.6 MB/s eta 0:00:00\n",
      "Collecting dnspython<3.0.0,>=1.16.0\n",
      "  Downloading dnspython-2.3.0-py3-none-any.whl (283 kB)\n",
      "     -------------------------------------- 283.7/283.7 kB 5.8 MB/s eta 0:00:00\n",
      "Installing collected packages: dnspython, pymongo\n",
      "Successfully installed dnspython-2.3.0 pymongo-4.4.1\n"
     ]
    }
   ],
   "source": [
    "pip install pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jrgar\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = webdriver.Chrome(**executable_path)\n",
    "\n",
    "# Navigate to the Mars NASA news site\n",
    "url = \"https://redplanetscience.com\"\n",
    "browser.get(url)\n",
    "\n",
    "\n",
    "#Extract the elements\n",
    "articles = browser.find_elements(By.CLASS_NAME, \"list_text\")\n",
    "\n",
    "news_list = []\n",
    "for article in articles:\n",
    "    title_element = article.find_element(By.CLASS_NAME, \"content_title\")\n",
    "    summary_element = article.find_element(By.CLASS_NAME, \"article_teaser_body\")\n",
    "\n",
    "    title = title_element.text.strip()\n",
    "    summary = summary_element.text.strip()\n",
    "\n",
    "    news_dict = {'title': title, 'preview': summary}\n",
    "    news_list.append(news_dict)\n",
    "\n",
    "# Exit\n",
    "browser.quit()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export data to JSON\n",
    "\n",
    "with open(\"mars_nasa_news.json\", \"w\") as json_file:\n",
    "    json.dump(news_list, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'Two of a Space Kind: Apollo 12 and Mars 2020', 'preview': 'Apollo 12 and the upcoming Mars 2020 mission may be separated by half a century, but they share several goals unique in the annals of space exploration.'}\n",
      "{'title': 'Scientists Explore Outback as Testbed for Mars', 'preview': \"Australia provides a great place for NASA's Mars 2020 and the ESA-Roscosmos ExoMars scientists to hone techniques in preparation for searching for signs ancient life on Mars.\"}\n",
      "{'title': \"NASA's New Mars Rover Will Use X-Rays to Hunt Fossils\", 'preview': \"PIXL, an instrument on the end of the Perseverance rover's arm, will search for chemical fingerprints left by ancient microbes.\"}\n",
      "{'title': \"A Martian Roundtrip: NASA's Perseverance Rover Sample Tubes\", 'preview': \"Marvels of engineering, the rover's sample tubes must be tough enough to safely bring Red Planet samples on the long journey back to Earth in immaculate condition.\"}\n",
      "{'title': \"6 Things to Know About NASA's Ingenuity Mars Helicopter\", 'preview': 'The first helicopter attempting to fly on another planet is a marvel of engineering. Get up to speed with these key facts about its plans.'}\n",
      "{'title': \"NASA's MAVEN Observes Martian Night Sky Pulsing in Ultraviolet Light\", 'preview': 'Vast areas of the Martian night sky pulse in ultraviolet light, according to images from NASA’s MAVEN spacecraft. The results are being used to illuminate complex circulation patterns in the Martian atmosphere.'}\n",
      "{'title': \"Newfound Martian Aurora Actually the Most Common; Sheds Light on Mars' Changing Climate\", 'preview': 'A type of Martian aurora first identified by NASA’s MAVEN spacecraft in 2016 is actually the most common form of aurora occurring on the Red Planet, according to new results from the mission.'}\n",
      "{'title': \"How NASA's Perseverance Mars Team Adjusted to Work in the Time of Coronavirus\", 'preview': 'Like much of the rest of the world, the Mars rover team is pushing forward with its mission-critical work while putting the health and safety of their colleagues and community first.'}\n",
      "{'title': \"NASA's Curiosity Keeps Rolling As Team Operates Rover From Home\", 'preview': 'The team has learned to meet new challenges as they work remotely on the Mars mission.'}\n",
      "{'title': \"NASA's Mars 2020 Rover Completes Its First Drive\", 'preview': 'In a 10-plus-hour marathon, the rover steered, turned and drove in 3-foot (1-meter) increments over small ramps.'}\n",
      "{'title': \"The Detective Aboard NASA's Perseverance Rover\", 'preview': 'An instrument called SHERLOC will, with the help of its partner WATSON, hunt for signs of ancient life by detecting organic molecules and minerals.'}\n",
      "{'title': 'NASA to Broadcast Mars 2020 Perseverance Launch, Prelaunch Activities', 'preview': 'Starting July 27, news activities will cover everything from mission engineering and science to returning samples from Mars to, of course, the launch itself.'}\n",
      "{'title': 'My Culture, My Voice', 'preview': 'In honor of Hispanic Heritage Month, Christina Hernandez, an instrument engineer on the Mars 2020 mission, talks about her childhood and journey to NASA.'}\n",
      "{'title': \"NASA's Perseverance Rover Is Midway to Mars\", 'preview': \"Sometimes half measures can be a good thing – especially on a journey this long. The agency's latest rover only has about 146 million miles left to reach its destination.\"}\n",
      "{'title': 'MOXIE Could Help Future Rockets Launch Off Mars', 'preview': \"NASA's Perseverance rover carries a device to convert Martian air into oxygen that, if produced on a larger scale, could be used not just for breathing, but also for fuel.\"}\n"
     ]
    }
   ],
   "source": [
    "# Print the list of dicts\n",
    "for news_item in news_list:\n",
    "    print(news_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jrgar\\AppData\\Roaming\\Python\\Python37\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  import sys\n"
     ]
    },
    {
     "ename": "ServerSelectionTimeoutError",
     "evalue": "localhost:27017: [WinError 10061] No connection could be made because the target machine actively refused it, Timeout: 30s, Topology Description: <TopologyDescription id: 64baf92366b7799593e569f7, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('localhost:27017: [WinError 10061] No connection could be made because the target machine actively refused it')>]>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mServerSelectionTimeoutError\u001b[0m               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12036\\2650737719.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[0mdb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"mars_news_db\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[0mcollection\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"news_collection\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m \u001b[0mcollection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert_many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnews_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\site-packages\\pymongo\\_csot.py\u001b[0m in \u001b[0;36mcsot_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    104\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0m_TimeoutContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcsot_wrapper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\site-packages\\pymongo\\collection.py\u001b[0m in \u001b[0;36minsert_many\u001b[1;34m(self, documents, ordered, bypass_document_validation, session, comment)\u001b[0m\n\u001b[0;32m    723\u001b[0m         \u001b[0mblk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_Bulk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mordered\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbypass_document_validation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcomment\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcomment\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    724\u001b[0m         \u001b[0mblk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 725\u001b[1;33m         \u001b[0mblk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrite_concern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    726\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mInsertManyResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minserted_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwrite_concern\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macknowledged\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\site-packages\\pymongo\\bulk.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, write_concern, session)\u001b[0m\n\u001b[0;32m    512\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 514\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwrite_concern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\site-packages\\pymongo\\bulk.py\u001b[0m in \u001b[0;36mexecute_command\u001b[1;34m(self, generator, write_concern, session)\u001b[0m\n\u001b[0;32m    388\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m         \u001b[0mclient\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatabase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 390\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mclient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tmp_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    391\u001b[0m             \u001b[0mclient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_retry_with_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_retryable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretryable_bulk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    392\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"generator didn't yield\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\site-packages\\pymongo\\mongo_client.py\u001b[0m in \u001b[0;36m_tmp_session\u001b[1;34m(self, session, close)\u001b[0m\n\u001b[0;32m   1773\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1774\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1775\u001b[1;33m         \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1776\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1777\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\site-packages\\pymongo\\mongo_client.py\u001b[0m in \u001b[0;36m_ensure_session\u001b[1;34m(self, session)\u001b[0m\n\u001b[0;32m   1756\u001b[0m             \u001b[1;31m# Don't make implicit sessions causally consistent. Applications\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1757\u001b[0m             \u001b[1;31m# should always opt-in.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1758\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__start_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcausal_consistency\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1759\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mConfigurationError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mInvalidOperation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1760\u001b[0m             \u001b[1;31m# Sessions not supported.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\site-packages\\pymongo\\mongo_client.py\u001b[0m in \u001b[0;36m__start_session\u001b[1;34m(self, implicit, **kwargs)\u001b[0m\n\u001b[0;32m   1701\u001b[0m         \u001b[1;31m# Raises ConfigurationError if sessions are not supported.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1702\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mimplicit\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1703\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_topology\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_implicit_session_support\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1704\u001b[0m             \u001b[0mserver_session\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_EmptyServerSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1705\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\site-packages\\pymongo\\topology.py\u001b[0m in \u001b[0;36m_check_implicit_session_support\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    536\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_implicit_session_support\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 538\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_session_support\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_session_support\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\site-packages\\pymongo\\topology.py\u001b[0m in \u001b[0;36m_check_session_support\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    553\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_description\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadable_servers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m                 self._select_servers_loop(\n\u001b[1;32m--> 555\u001b[1;33m                     \u001b[0mreadable_server_selector\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_server_selection_timeout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    556\u001b[0m                 )\n\u001b[0;32m    557\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonData\\lib\\site-packages\\pymongo\\topology.py\u001b[0m in \u001b[0;36m_select_servers_loop\u001b[1;34m(self, selector, timeout, address)\u001b[0m\n\u001b[0;32m    237\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mnow\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mend_time\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m                 raise ServerSelectionTimeoutError(\n\u001b[1;32m--> 239\u001b[1;33m                     \u001b[1;34mf\"{self._error_message(selector)}, Timeout: {timeout}s, Topology Description: {self.description!r}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    240\u001b[0m                 )\n\u001b[0;32m    241\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mServerSelectionTimeoutError\u001b[0m: localhost:27017: [WinError 10061] No connection could be made because the target machine actively refused it, Timeout: 30s, Topology Description: <TopologyDescription id: 64baf92366b7799593e569f7, topology_type: Unknown, servers: [<ServerDescription ('localhost', 27017) server_type: Unknown, rtt: None, error=AutoReconnect('localhost:27017: [WinError 10061] No connection could be made because the target machine actively refused it')>]>"
     ]
    }
   ],
   "source": [
    "# Export data to MongoDB\n",
    "\n",
    "import pymongo\n",
    "\n",
    "#Configure browser\n",
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = webdriver.Chrome(**executable_path)\n",
    "\n",
    "# Navigate site\n",
    "url = \"https://redplanetscience.com\"\n",
    "browser.get(url)\n",
    "\n",
    "# Find and extract the elements\n",
    "articles = browser.find_elements(By.CLASS_NAME, \"list_text\")\n",
    "\n",
    "news_list = []\n",
    "for article in articles:\n",
    "    title_element = article.find_element(By.CLASS_NAME, \"content_title\")\n",
    "    summary_element = article.find_element(By.CLASS_NAME, \"article_teaser_body\")\n",
    "\n",
    "    title = title_element.text.strip()\n",
    "    summary = summary_element.text.strip()\n",
    "\n",
    "    news_dict = {'title': title, 'preview': summary}\n",
    "    news_list.append(news_dict)\n",
    "\n",
    "# Close \n",
    "browser.quit()\n",
    "\n",
    "# Export the data to MongoDB\n",
    "client = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "db = client[\"mars_news_db\"]\n",
    "collection = db[\"news_collection\"]\n",
    "collection.insert_many(news_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Print the list of dictionaries (optional)\n",
    "for news_item in news_list:\n",
    "    print(news_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
